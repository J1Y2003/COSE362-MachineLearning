{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","mount_file_id":"1IQoGgGCxYRk_P41kbGQk49ftfuU4hPOu","authorship_tag":"ABX9TyPuvSerXQpgT9HKjoMx+JJK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Preparation"],"metadata":{"id":"DlNld6wIu1kh"}},{"cell_type":"markdown","source":["### Mounting Google Drive"],"metadata":{"id":"GkGazbF1uyT6"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"b4b-AZdFKcea","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728663897282,"user_tz":-540,"elapsed":3492,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"outputId":"1a4363f8-03bc-4fc1-ff69-89fd20d00dd0"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### Importing Relevant Libraries and moving to location of data file"],"metadata":{"id":"JtruxmyXuthw"}},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmlIoD3OUi4v","executionInfo":{"status":"ok","timestamp":1728663897282,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"outputId":"6c8e4665-2e83-4ad4-cb16-f29f23283b5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/2학년 2학기/COSE362-MachineLearning/Hw1\n"]}],"source":["import torch\n","%cd /content/drive/MyDrive/2학년 2학기/COSE362-MachineLearning/Hw1"]},{"cell_type":"markdown","source":["### Checking GPU available for acceleration"],"metadata":{"id":"iUyjfUfruply"}},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    print(\"GPU is enabled and available!\")\n","    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n","else:\n","    print(\"GPU is not enabled or available. Check the Runtime Type.\")"],"metadata":{"id":"8FBXlHXH65nE","executionInfo":{"status":"ok","timestamp":1728663897282,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5de7267c-d287-4f21-e9da-368cc7e6abd2"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is enabled and available!\n","Using GPU: NVIDIA A100-SXM4-40GB\n"]}]},{"cell_type":"markdown","source":["## GMM class implementation"],"metadata":{"id":"YlI56mxAulqs"}},{"cell_type":"code","source":["from torch.distributions import MultivariateNormal as MVN #importing MultivariateNormal class from torch.distributions.\n","\n","class GMM:\n","  #upon initiation of class, the weights/means/covariance matrices of c(number of components) different MultiVariate Normal distributions(MVN) are intialized.\n","  def __init__(self, data, c):\n","    self.weights = torch.tensor([1/c for i in range(c)], device=\"cuda\") #initial: even weights\n","    self.means = data[torch.randint(len(data), (c,))] #initial: random data point chosen as mean for each MVN\n","    self.cov_matrices = torch.stack([torch.cov(data.T) for _ in range(c)]).to(\"cuda\") #initial: covariance matrix of data points used as initial values for each MVN\n","    self.data = data\n","    self.c = c\n","\n","  #this method accounts for the \"Expectation\" step of the EM algorithm. It also returns the \"old\" likelihood later used to check convergence.\n","  def expectation(self):\n","    GMMs = MVN(loc = self.means, covariance_matrix = self.cov_matrices) #the MultivariateNormal class supports batch calculations, hence c number of parameters are all passed at the same time.\n","    log_prob = GMMs.log_prob(self.data.unsqueeze(1)) #log_prob has a shape of (c, t, k) where t is the number of observations, and k is the number of featuers.\n","    weighted_log_prob = log_prob + torch.log(self.weights) #notice log calculations were used for numeric stability\n","    weighted_log_sum = torch.logsumexp(weighted_log_prob, dim=1)\n","    self.responsibility = torch.exp(weighted_log_prob - weighted_log_sum.unsqueeze(1)) #responsibility matrix of shape (t,k) calculated\n","    return torch.sum(weighted_log_sum) #returning the likelihood mentioned before\n","\n","\n","  #this method accounts for the \"Maximization\" step of the EM algorithm. It also returns the \"new\" likelihood later used to check convergence.\n","  def maximize(self):\n","    #calculations for the weights, means, covariance matrices are all in the slides. Notice how all calculations were vectorized in order to lower computational cost\n","    self.weights = torch.sum(self.responsibility, 0) / len(self.responsibility)\n","    self.means = torch.div((self.data.T@self.responsibility).T, torch.sum(self.responsibility, 0).unsqueeze(1))\n","    centered_data = torch.sub(self.data, self.means.unsqueeze(1))\n","    weighted_centered_data = centered_data * self.responsibility.T.unsqueeze(-1)\n","    self.cov_matrices = torch.bmm(torch.transpose(centered_data, 1, 2), weighted_centered_data) / torch.sum(self.responsibility, 0).unsqueeze(1).unsqueeze(1)\n","\n","    #ensuring positive definiteness of covariance matrix by ensuring symmmetry and adding small epsilon value to the diagonal.\n","    self.cov_matrices += torch.diag_embed(torch.full((self.c, self.cov_matrices.shape[-1]), 1e-3, device=\"cuda\")) #tests revealed that epsilon of 1e-3 does not alter results\n","    self.cov_matrices = (self.cov_matrices + torch.transpose(self.cov_matrices, 1, 2)) / 2\n","\n","    #calculating and returning \"new\" likelihood\n","    GMMs = MVN(loc = self.means, covariance_matrix = self.cov_matrices)\n","    log_prob = GMMs.log_prob(self.data.unsqueeze(1))\n","    weighted_log_prob = log_prob + torch.log(self.weights)\n","    weighted_log_sum = torch.logsumexp(weighted_log_prob, dim=1)\n","    return torch.sum(weighted_log_sum)\n","\n","  #log_likelihood of each observation in input data. Note that in previous methods a single log_likelihood of the entire dataset were returned.\n","  def log_likelihood(self, input_data):\n","    GMMs = MVN(loc = self.means, covariance_matrix = self.cov_matrices)\n","    log_prob = GMMs.log_prob(input_data.unsqueeze(1))\n","    weighted_log_prob = log_prob + torch.log(self.weights)\n","    weighted_log_sum = torch.logsumexp(weighted_log_prob, dim=1)\n","    return weighted_log_sum\n","\n","  #this method performs the EM algorithm, with maximum iteration of 1000 and a tolerance of 1e-4.\n","  def EM(self, max_iter=1000, tol=1e-4):\n","        for i in range(max_iter):\n","          log_likelihood = self.expectation()\n","          new_likelihood = self.maximize()\n","          if i == (max_iter - 1) or abs(new_likelihood - log_likelihood) < tol: #checking convergence\n","              break"],"metadata":{"id":"PkREeoKthSk_","executionInfo":{"status":"ok","timestamp":1728664034290,"user_tz":-540,"elapsed":712,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["## Using GMM class to perform classification"],"metadata":{"id":"beeY9NvSu_H7"}},{"cell_type":"markdown","source":["### Data Preparation"],"metadata":{"id":"1rmxv4zZuhGq"}},{"cell_type":"code","source":["#this is the K value for the K-fold validation. Higher K values would lead to better utilization of limited data.\n","K = 5\n","\n","#reading training data(including labels) and converting to a tensor.\n","train_file_path = \"train.txt\"\n","with open(train_file_path, 'r') as f:\n","  train_data = f.readlines()\n","data_with_label = []\n","for data in train_data:\n","  data_with_label.append([float(x) for x in data.split()])\n","data_with_label = torch.tensor(data_with_label, dtype=torch.float, device=\"cuda\")\n","\n","#full dataset divided into class 0/1.\n","data_class = data_with_label[:, -1]\n","data_0 = data_with_label[data_class==0]\n","data_1 = data_with_label[data_class==1]\n","\n","#computing the size of the K data sections\n","section_size_0 = len(data_0) // K\n","section_size_1 = len(data_1) // K\n","\n","#preparing train data for K fold:\n","data_sections_0 = torch.zeros([K, section_size_0, 14], device=\"cuda\") #initializing the tensor that will contain each data section(shape: (K, section size, #feature + 1)).\n","data_sections_1 = torch.zeros([K, section_size_1, 14], device=\"cuda\")\n","train_sections_0 = torch.zeros([K, (K - 1) * (section_size_0), 13], device=\"cuda\") #intializing the tensor that will contain training data for each K-fold.\n","train_sections_1 = torch.zeros([K, (K - 1) * (section_size_1), 13], device=\"cuda\")\n","for k in range(K): #first filling in data section\n","  data_sections_0[k] = data_0[k * section_size_0 : (k + 1) * section_size_0]\n","  data_sections_1[k] = data_1[k * section_size_1 : (k + 1) * section_size_1]\n","for k in range(K): #filling in training data, notice how labels are excluded.\n","  train_sections_0[k] = torch.cat((data_sections_0[:k, :, :-1], data_sections_0[k + 1:, :, :-1])).flatten(end_dim=1)\n","  train_sections_1[k] = torch.cat((data_sections_1[:k, :, :-1], data_sections_1[k + 1:, :, :-1])).flatten(end_dim=1)\n","\n","#preparing test data for K fold:\n","test_sections = torch.zeros([K, section_size_0 + section_size_1, 14], device=\"cuda\") #initializing tensor that will contain test data for each K-fold.\n","for k in range(K): #filling in test data\n","  test_sections[k] = torch.cat((data_sections_0[k], data_sections_1[k]))"],"metadata":{"id":"g8Is8vKFWr4U","executionInfo":{"status":"ok","timestamp":1728667410238,"user_tz":-540,"elapsed":585,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":["### Finding optimal c"],"metadata":{"id":"_-e_08m6ubF7"}},{"cell_type":"markdown","source":["**The optimal number of components (c) found can vary due to the stochastic nature of the initialization of the GMM models. Hence the optimal number of components used for the documentation (8) was chosen based on the average error rate for 20 consecutive trials.**"],"metadata":{"id":"eV5AZY4GwHro"}},{"cell_type":"markdown","source":["*Due to numeric stability issues(underflows, overflows, etc.), there is an extremely low chance of a singular covariance matrix raising a ValueError for the .fit() method despite the precautions took before. In the case that occurs, simply rerun the code.*"],"metadata":{"id":"Uw21p0IKvP-u"}},{"cell_type":"code","source":["#top bound for # of components to be evaluated\n","C = 20\n","\n","errors = [] #array that will contain error data for each # of components\n","for c in range(2, C + 1):\n","  error = 0 #used to average the error of each K-fold\n","  for k in range(K): #start K-fold validation\n","\n","    #initializing GMM for class 0 and class 1\n","    GMM_0 = GMM(train_sections_0[k], c)\n","    GMM_1 = GMM(train_sections_1[k], c)\n","\n","    #EM algorithm on GMM until convergence\n","    GMM_0.EM()\n","    GMM_1.EM()\n","\n","    #calculating log_likelihood for unlabeled observations in current test data\n","    GMM_0_likelihood = GMM_0.log_likelihood(test_sections[k, :, :-1])\n","    GMM_1_likelihood = GMM_1.log_likelihood(test_sections[k, :, :-1])\n","\n","    #true_class from test data\n","    true_class = test_sections[k, :, -1]\n","\n","    #classification by comparing the sizes of the log_likelihood of GMM_0 and GMM_1\n","    model_likelihood = torch.cat((GMM_0_likelihood.unsqueeze(1), GMM_1_likelihood.unsqueeze(1)), 1)\n","    model_class = torch.argmax(model_likelihood, dim=1).to(\"cuda\")\n","\n","    #calculating error by averaging the difference of the true and model class. This works as data can only be classified into 0 or 1.\n","    error += torch.mean(abs(model_class - true_class))\n","\n","  #K-fold complete for current component, the error across K-tests are averaged and added to the errors array intialized before.\n","  print(\"accuracy for component\", c, \":\", float(error/K))\n","  errors.append(float(error/K))\n","\n","#component analysis complete, optimal_c can now be found\n","optimal_c = torch.argmin(torch.tensor(errors)) + 2 #since the loop starts from 2, we add it to the index.\n","print(\"optimal c for single trial:\", int(optimal_c))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_NtPTzfBBL2","executionInfo":{"status":"ok","timestamp":1728669372142,"user_tz":-540,"elapsed":378009,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"outputId":"b5a47c83-7d1d-486c-a6bf-eeca0b936d9b"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for component 2 : 0.15627072751522064\n","accuracy for component 3 : 0.15184138715267181\n","accuracy for component 4 : 0.15084604918956757\n","accuracy for component 5 : 0.1505972146987915\n","accuracy for component 6 : 0.14850696921348572\n","accuracy for component 7 : 0.1479761153459549\n","accuracy for component 8 : 0.14737890660762787\n","accuracy for component 9 : 0.14837424457073212\n","accuracy for component 10 : 0.1478434056043625\n","accuracy for component 11 : 0.14795951545238495\n","accuracy for component 12 : 0.14761114120483398\n","accuracy for component 13 : 0.14759455621242523\n","accuracy for component 14 : 0.14865627884864807\n","accuracy for component 15 : 0.1480092853307724\n","accuracy for component 16 : 0.14812541007995605\n","accuracy for component 17 : 0.1480424702167511\n","accuracy for component 18 : 0.1479761153459549\n","accuracy for component 19 : 0.1482415497303009\n","accuracy for component 20 : 0.14840742945671082\n","optimal c for single trial: 8\n"]}]},{"cell_type":"markdown","source":["### Final error calculation for optimal c"],"metadata":{"id":"ty_EQ-kjuR-7"}},{"cell_type":"code","source":["#reading test data(including labels) and converting to a tensor.\n","test_file_path = \"test.txt\"\n","with open(test_file_path, 'r') as f:\n","  test_data = f.readlines()\n","test_data_l = []\n","for data in test_data:\n","  test_data_l.append([float(x) for x in data.split()])\n","test_data_l = torch.tensor(test_data_l, device=\"cuda\")\n","\n","#extracting class and data used to calculate log likelihood\n","test_true_class = test_data_l[:, -1]\n","test_data_nl = test_data_l[:, :-1]\n","\n","#using previously prepared data to train the final GMM for class 0 and 1, using optimal c.\n","GMM_final_0 = GMM(data_0[:, :-1], optimal_c)\n","GMM_final_1 = GMM(data_1[:, :-1], optimal_c)\n","GMM_final_0.EM()\n","GMM_final_1.EM()\n","\n","#classification and error calculation done similarly as before.\n","GMM_0_final_likelihood = GMM_final_0.log_likelihood(test_data_nl)\n","GMM_1_final_likelihood = GMM_final_1.log_likelihood(test_data_nl)\n","final_model_likelihood = torch.cat((GMM_0_final_likelihood.unsqueeze(1), GMM_1_final_likelihood.unsqueeze(1)), 1)\n","final_model_class = torch.argmax(final_model_likelihood, dim=1).to(\"cuda\")\n","final_error = torch.mean(abs(final_model_class - test_true_class))\n","print(\"Final error with optimal number of components:\", float(final_error))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S4HbPTP_F_zY","executionInfo":{"status":"ok","timestamp":1728669381280,"user_tz":-540,"elapsed":2228,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"outputId":"f343b48a-7961-4e25-86af-9a419f7ad93e"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Final error with optimal number of components: 0.1467820405960083\n"]}]}]}