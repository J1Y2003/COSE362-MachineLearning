{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["TqcqC22O0kIn"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Importing relevent libraries and reading data files"],"metadata":{"id":"TqcqC22O0kIn"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"keggUKz15-hl","executionInfo":{"status":"ok","timestamp":1728031900347,"user_tz":-540,"elapsed":2267,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"outputId":"c86d1ea9-8f65-4466-e786-138107f697d6"},"execution_count":313,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":314,"metadata":{"collapsed":true,"id":"2zZCGwmKZ1yR","executionInfo":{"status":"ok","timestamp":1728031900348,"user_tz":-540,"elapsed":7,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"outputs":[],"source":["import numpy as np\n","import scipy as sp\n","\n","training_data_and_class = np.loadtxt(\"/content/drive/MyDrive/2학년 2학기/COSE362-MachineLearning/Hw1/train.txt\") #(60290, 14(13 feature + 1 class))\n","#training_data_and_class = np.loadtxt(\"/content/drive/MyDrive/2학년 2학기/COSE362-MachineLearning/Hw1/personal_test.txt\")"]},{"cell_type":"markdown","source":["### Self-defined functions"],"metadata":{"id":"MhvZRU9MmM1I"}},{"cell_type":"code","source":["def compute_responsibilities_vectorized(theta, data, K):\n","  \"\"\"Vectorized computation of responsibilities.\"\"\"\n","  component_dist, means, covariances = theta\n","  data_size, feat_dim = data.shape\n","\n","  # Precompute the multivariate normal densities for all components and all data points\n","  prob_matrix = np.zeros((data_size, K))\n","  for k in range(K):\n","      prob_matrix[:, k] = sp.stats.multivariate_normal.pdf(data, means[k], covariances[k], allow_singular=True) * component_dist[k]\n","\n","  # Calculate responsibilities by normalizing over all components\n","  responsibility_matrix = prob_matrix / prob_matrix.sum(axis=1, keepdims=True)\n","  return responsibility_matrix"],"metadata":{"id":"XHjxYNHvi7D2","executionInfo":{"status":"ok","timestamp":1728031900348,"user_tz":-540,"elapsed":6,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"execution_count":315,"outputs":[]},{"cell_type":"code","source":["def GMM_likelihood(theta_list, xt): #calculates likelihood of xt given GMM parameters\n","  responsibility, mean_list, cov_list = theta_list\n","  likelihood = 0\n","  for c in range(len(responsibility)):\n","    likelihood += sp.stats.multivariate_normal.pdf(xt, mean_list[c], cov_list[c], allow_singular=True) * responsibility[c]\n","\n","  return likelihood"],"metadata":{"id":"DEqDugSsa0aI","executionInfo":{"status":"ok","timestamp":1728031900348,"user_tz":-540,"elapsed":6,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"execution_count":316,"outputs":[]},{"cell_type":"code","source":["def MSE_of_model(model_theta, test_data):\n","  N = np.shape(test_data)[0]\n","  feature_data = test_data[:, :-1]\n","  true_class = test_data[:,-1]\n","  label = true_class[0]\n","  if label == 0:\n","    model_class = np.ones(np.shape(true_class))\n","  else:\n","    model_class = np.zeros(np.shape(true_class))\n","\n","  for i, xt in enumerate(feature_data):\n","    model_class[i] = data_binary_classifier()\n","\n","\n","  print(\"model_class example:\", model_class[:10])\n","  print(\"true_class example:\", true_class[:10])\n","  return np.mean((true_class - model_class) ** 2)"],"metadata":{"id":"1RByFnhmg3F5","executionInfo":{"status":"ok","timestamp":1728031900348,"user_tz":-540,"elapsed":6,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"execution_count":317,"outputs":[]},{"cell_type":"code","source":["def data_binary_classifier(theta_0, theta_1, data):\n","  model_class = []\n","  for xt in data:\n","    if (GMM_likelihood(theta_0, xt) > GMM_likelihood(theta_1, xt)):\n","      model_class.append(0)\n","    else:\n","      model_class.append(1)\n","  return np.array(model_class)"],"metadata":{"id":"jO2m2B3Wmn5Q","executionInfo":{"status":"ok","timestamp":1728031900348,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"execution_count":318,"outputs":[]},{"cell_type":"markdown","source":["### GMM model"],"metadata":{"id":"TcW1NtlZPyo_"}},{"cell_type":"code","source":["def GMM_training(data, K):\n","  data_size, feat_dim = np.shape(data)\n","\n","  #initialization\n","\n","  component_dist = np.zeros((K,))\n","  mean_k = np.zeros((K, feat_dim))\n","  cov_k = np.zeros((K, feat_dim, feat_dim))\n","  component_dist[:] = 1/K #(K,)\n","  mean_k = data[np.random.choice(data.shape[0], size=K, replace=False)].reshape(K, feat_dim)\n","  cov_init = np.cov(data, rowvar=False)\n","  cov_k[:] = cov_init #(K, feat_dim, feat_dim)\n","  theta = [component_dist, mean_k, cov_k]\n","  convergence = 0\n","\n","  #iteration until theta convergence\n","  while True:\n","    #Expectation\n","    responsibility = compute_responsibilities_vectorized(theta, data, K)\n","    #Mazimization\n","    new_component_dist = np.zeros(np.shape(component_dist))\n","    new_mean_k = np.zeros(np.shape(mean_k))\n","    new_cov_k = np.zeros(np.shape(cov_k))\n","\n","    for k in range(K):\n","      new_mean_k_num = np.zeros((feat_dim,))\n","      new_cov_k_num = np.zeros((feat_dim, feat_dim))\n","      new_mean_k_denum = 0\n","      for t in range(data_size):\n","        new_component_dist[k] += responsibility[t][k]\n","        new_mean_k_num += responsibility[t][k] * data[t]\n","        new_cov_k_num += responsibility[t][k] * np.outer(data[t], data[t])\n","        new_mean_k_denum += responsibility[t][k]\n","\n","      new_component_dist[k] /= data_size\n","      new_mean_k[k] = new_mean_k_num / new_mean_k_denum\n","      new_cov_k[k] = (new_cov_k_num / new_mean_k_denum) - np.outer(new_mean_k[k], new_mean_k[k])\n","\n","    new_theta = [new_component_dist, new_mean_k, new_cov_k]\n","\n","    old_component_dist, old_means, old_covariances = theta\n","    new_component_dist, new_means, new_covariances = new_theta\n","\n","    # Check for changes in means, covariances, and component distributions\n","    mean_ratio = np.mean(abs(new_means / old_means))\n","    cov_ratio = np.mean([np.mean(abs(new_covariances[i] / old_covariances[i])) for i in range(len(old_covariances))])\n","    comp_dist_ratio = np.mean(abs(new_component_dist / old_component_dist))\n","    total_diff = abs((sum([mean_ratio, cov_ratio, comp_dist_ratio]) / 3) - 1)\n","    if (convergence > 3):\n","      break\n","    if (total_diff < 10 ** -2):\n","      convergence += 1\n","    else:\n","      convergence = 0\n","    theta = new_theta\n","\n","  return new_theta"],"metadata":{"id":"OC3zVPwpAaK7","executionInfo":{"status":"ok","timestamp":1728031900802,"user_tz":-540,"elapsed":459,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"execution_count":319,"outputs":[]},{"cell_type":"markdown","source":["### Training"],"metadata":{"id":"yKlSlJvif7Fy"}},{"cell_type":"code","source":["true_class = training_data_and_class[:, -1] #(60290,)\n","data_0 = training_data_and_class[:, :][true_class == 0] #(60290, 13)\n","data_1 = training_data_and_class[:, :][true_class == 1]\n","\n","#Preparing for K-fold cross validation(K=5)\n","use_size_0 = (np.shape(data_0)[0] // 5) * 5\n","use_size_1 = (np.shape(data_1)[0] // 5) * 5\n","\n","data_0_split = [row for row in np.reshape(data_0[:use_size_0], (5, -1, 14))]\n","data_1_split = [row for row in np.reshape(data_1[:use_size_1], (5, -1, 14))]\n","total_error_2t6 = np.zeros((5,))\n","for c in range(2,7): #number of mixture components\n","  print()\n","  print(\"mixture component:\", c)\n","  MSE_per_component = 0\n","  for K in range(5):\n","    print(\"data section:\", K + 1)\n","    test_data = np.concatenate((data_0_split[K], data_1_split[K]))\n","\n","    train_data_0 = np.concatenate(data_0_split[:K] + data_0_split[K+1:])\n","    train_data_1 = np.concatenate(data_1_split[:K] + data_1_split[K+1:])\n","    train_data_0_nl = train_data_0[:,:-1]\n","    train_data_1_nl = train_data_1[:,:-1]\n","\n","    GMM_0_theta = GMM_training(train_data_0_nl, c)\n","    print(\"done training GMM_0\")\n","    GMM_1_theta = GMM_training(train_data_1_nl, c)\n","    print(\"done training GMM_1\")\n","\n","    #test model, create a estimate class\n","    test_data_nl = test_data[:, :-1]\n","    test_true_class = test_data[:, -1]\n","    test_model_class = data_binary_classifier(GMM_0_theta, GMM_1_theta, test_data_nl)\n","\n","    #calculate MSE\n","    MSE_per_component_part = np.mean((test_true_class - test_model_class) ** 2)\n","    MSE_per_component += MSE_per_component_part #this is the MSE for one data section of K division\n","    print(\"MSE value for one division:\", MSE_per_component_part)\n","  print(\"Done calculating MSE for c =\", c)\n","  print(\"MSE value for\", c, \"is:\", MSE_per_component/5)\n","  total_error_2t6[c - 2] = MSE_per_component / 5\n","\n","print(\"total error across 2 ~ 6 mixture components:\", total_error_2t6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BCAAyXq9f6Sw","outputId":"51561165-81a8-47a6-93a4-b489c096f821"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","mixture component: 2\n","data section: 1\n","done training GMM_0\n","done training GMM_1\n","MSE value for one division: 0.15493074562494816\n","data section: 2\n","done training GMM_0\n","done training GMM_1\n","MSE value for one division: 0.1297171767438003\n","data section: 3\n","done training GMM_0\n","done training GMM_1\n","MSE value for one division: 0.1795637389068591\n","data section: 4\n","done training GMM_0\n","done training GMM_1\n","MSE value for one division: 0.1598241685328025\n","data section: 5\n"]}]}]}