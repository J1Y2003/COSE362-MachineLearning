{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","mount_file_id":"1IQoGgGCxYRk_P41kbGQk49ftfuU4hPOu","authorship_tag":"ABX9TyPxB+VjqMahdDm3RYaEqKqI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"b4b-AZdFKcea","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728638117638,"user_tz":-540,"elapsed":14841,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"outputId":"cc08d8ec-9005-487d-a420-e6ea793a8f04"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmlIoD3OUi4v","executionInfo":{"status":"ok","timestamp":1728638121192,"user_tz":-540,"elapsed":3559,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"outputId":"6f3f18a4-8e71-4e6a-e30a-46d7810f4f40","cellView":"form"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/2학년 2학기/COSE362-MachineLearning/Hw1\n"]}],"source":["# @title Importing Relevent Libraries\n","import torch\n","%cd drive/MyDrive/2학년 2학기/COSE362-MachineLearning/Hw1"]},{"cell_type":"code","source":["# @title Checking GPU availibity\n","if torch.cuda.is_available():\n","    print(\"GPU is enabled and available!\")\n","    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n","else:\n","    print(\"GPU is not enabled or available, working with CPU...\")"],"metadata":{"id":"8FBXlHXH65nE","executionInfo":{"status":"aborted","timestamp":1728639399792,"user_tz":-540,"elapsed":6,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title GMM implementation using class\n","from torch.distributions import MultivariateNormal as MVN\n","class GMM:\n","  def __init__(self, data, c):\n","    self.weights = torch.tensor([1/c for i in range(c)], device=\"cuda\")\n","    self.means = data[torch.randint(len(data), (c,))]\n","    self.cov_matrices = torch.stack([torch.cov(data.T) for _ in range(c)]).to(\"cuda\")\n","    self.data = data\n","    self.c = c\n","\n","  def expectation(self):\n","    GMMs = MVN(loc = self.means, covariance_matrix = self.cov_matrices)\n","    log_prob = GMMs.log_prob(self.data.unsqueeze(1))\n","    weighted_log_prob = log_prob + torch.log(self.weights)\n","    weighted_log_sum = torch.logsumexp(weighted_log_prob, dim=1)\n","    self.responsibility = torch.exp(weighted_log_prob - weighted_log_sum.unsqueeze(1))\n","    return torch.sum(weighted_log_sum)\n","\n","\n","\n","  def maximize(self):\n","    self.weights = torch.sum(self.responsibility, 0) / len(self.responsibility)\n","    self.means = torch.div((self.data.T@self.responsibility).T, torch.sum(self.responsibility, 0).unsqueeze(1))\n","    centered_data = torch.sub(self.data, self.means.unsqueeze(1))\n","    weighted_centered_data = centered_data * self.responsibility.T.unsqueeze(-1)\n","    self.cov_matrices = torch.bmm(torch.transpose(centered_data, 1, 2), weighted_centered_data) / torch.sum(self.responsibility, 0).unsqueeze(1).unsqueeze(1)\n","\n","    #ensuring positive definiteness\n","    self.cov_matrices += torch.diag_embed(torch.full((self.c, self.cov_matrices.shape[-1]), 1e-6, device=\"cuda\"))\n","    self.cov_matrices = (self.cov_matrices + torch.transpose(self.cov_matrices, 1, 2)) / 2\n","\n","    #returning new likelihood\n","    GMMs = MVN(loc = self.means, covariance_matrix = self.cov_matrices)\n","    log_prob = GMMs.log_prob(self.data.unsqueeze(1))\n","    weighted_log_prob = log_prob + torch.log(self.weights)\n","    weighted_log_sum = torch.logsumexp(weighted_log_prob, dim=1)\n","    return torch.sum(weighted_log_sum)\n","\n","  def log_likelihood(self, input_data): #returns t length vector\n","    GMMs = MVN(loc = self.means, covariance_matrix = self.cov_matrices)\n","    log_prob = GMMs.log_prob(input_data.unsqueeze(1))\n","    weighted_log_prob = log_prob + torch.log(self.weights)\n","    weighted_log_sum = torch.logsumexp(weighted_log_prob, dim=1)\n","    return weighted_log_sum\n","\n","  def fit(self, max_iter=1000, tol=1e-4):\n","        for i in range(max_iter):\n","            log_likelihood = self.expectation()\n","            new_likelihood = self.maximize()\n","            # Check convergence\n","            if i == (max_iter - 1) or abs(new_likelihood - log_likelihood) < tol:\n","                break\n","            prev_likelihood = new_likelihood"],"metadata":{"id":"PkREeoKthSk_","executionInfo":{"status":"ok","timestamp":1728640033014,"user_tz":-540,"elapsed":271,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# @title Data preparation\n","K = 5\n","train_file_path = \"train.txt\"\n","with open(train_file_path, 'r') as f:\n","  train_data = f.readlines()\n","data_with_label = []\n","for data in train_data:\n","  data_with_label.append([float(x) for x in data.split()])\n","#full dataset with label\n","data_with_label = torch.tensor(data_with_label, dtype=torch.float, device=\"cuda\")\n","data_class = data_with_label[:, -1]\n","#full dataset divided into class 0/1, with removed labels\n","data_0 = data_with_label[data_class==0]\n","data_1 = data_with_label[data_class==1]\n","\n","section_size_0 = len(data_0) // K\n","section_size_1 = len(data_1) // K\n","\n","#preparing train data\n","data_sections_0 = torch.zeros([K, len(data_0) // K, 14], device=\"cuda\")\n","data_sections_1 = torch.zeros([K, len(data_1) // K, 14], device=\"cuda\")\n","train_sections_0 = torch.zeros([K, (K - 1) * (len(data_0) // K), 13], device=\"cuda\")\n","train_sections_1 = torch.zeros([K, (K - 1) * (len(data_1) // K), 13], device=\"cuda\")\n","for k in range(K):\n","  data_sections_0[k] = data_0[k * section_size_0 : (k + 1) * section_size_0]\n","  data_sections_1[k] = data_1[k * section_size_1 : (k + 1) * section_size_1]\n","for k in range(K):\n","  train_sections_0[k] = torch.cat((data_sections_0[:k, :, :-1], data_sections_0[k + 1:, :, :-1])).flatten(end_dim=1)\n","  train_sections_1[k] = torch.cat((data_sections_1[:k, :, :-1], data_sections_1[k + 1:, :, :-1])).flatten(end_dim=1)\n","\n","#preparing test data\n","test_sections = torch.zeros([K, (len(data_0) // K) + (len(data_1) // K), 14], device=\"cuda\")\n","for k in range(K):\n","  test_sections[k] = torch.cat((data_sections_0[k], data_sections_1[k]))"],"metadata":{"id":"g8Is8vKFWr4U","executionInfo":{"status":"ok","timestamp":1728642166542,"user_tz":-540,"elapsed":637,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["C = 20\n","errors = []\n","for c in range(2, C):\n","  error = 0\n","  for k in range(K):\n","    GMM_0 = GMM(train_sections_0[k], c)\n","    GMM_1 = GMM(train_sections_1[k], c)\n","    GMM_0.fit()\n","    GMM_1.fit()\n","\n","    GMM_0_likelihood = GMM_0.log_likelihood(test_sections[k, :, :-1])\n","    GMM_1_likelihood = GMM_1.log_likelihood(test_sections[k, :, :-1])\n","    true_class = test_sections[k, :, -1]\n","    model_likelihood = torch.cat((GMM_0_likelihood.unsqueeze(1), GMM_1_likelihood.unsqueeze(1)), 1) #(# of data, 2)\n","    model_class = torch.argmax(model_likelihood, dim=1).to(\"cuda\")\n","    error += torch.mean(abs(model_class - true_class))\n","  print(\"accuracy for component\", c, \":\", float(error/K))\n","  errors.append(float(error/K))\n","optimal_c = torch.argmin(torch.tensor(errors)) + 2\n","print(\"optimal c:\", optimal_c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G_NtPTzfBBL2","executionInfo":{"status":"ok","timestamp":1728644041649,"user_tz":-540,"elapsed":165022,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"outputId":"82a566f5-a6b1-4726-fbc0-2c15e92478d4"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for component 2 : 0.15599235892295837\n","accuracy for component 3 : 0.151696115732193\n","accuracy for component 4 : 0.15149705111980438\n","accuracy for component 5 : 0.15041884779930115\n","accuracy for component 6 : 0.14950649440288544\n","accuracy for component 7 : 0.14864395558834076\n","accuracy for component 8 : 0.14867711067199707\n","accuracy for component 9 : 0.14826242625713348\n","accuracy for component 10 : 0.14847806096076965\n","accuracy for component 11 : 0.14876006543636322\n","accuracy for component 12 : 0.14912499487400055\n","accuracy for component 13 : 0.14884299039840698\n","accuracy for component 14 : 0.14945673942565918\n","accuracy for component 15 : 0.14930744469165802\n","accuracy for component 16 : 0.1485610008239746\n","accuracy for component 17 : 0.15141412615776062\n","accuracy for component 18 : 0.151762455701828\n","accuracy for component 19 : 0.15003731846809387\n","optimal c: tensor(9)\n"]}]},{"cell_type":"code","source":["test_file_path = \"test.txt\"\n","with open(test_file_path, 'r') as f:\n","  test_data = f.readlines()\n","test_data_l = []\n","for data in test_data:\n","  test_data_l.append([float(x) for x in data.split()])\n","test_data_l = torch.tensor(test_data_l, device=\"cuda\")\n","test_true_class = test_data_l[:, -1]\n","test_data_nl = test_data_l[:, :-1]\n","\n","GMM_final_0 = GMM(data_0[:, :-1], optimal_c)\n","GMM_final_1 = GMM(data_1[:, :-1], optimal_c)\n","GMM_final_0.fit()\n","GMM_final_1.fit()\n","\n","GMM_0_final_likelihood = GMM_final_0.log_likelihood(test_data_nl)\n","GMM_1_final_likelihood = GMM_final_1.log_likelihood(test_data_nl)\n","final_model_likelihood = torch.cat((GMM_0_final_likelihood.unsqueeze(1), GMM_1_final_likelihood.unsqueeze(1)), 1) #(# of data, 2)\n","final_model_class = torch.argmax(final_model_likelihood, dim=1).to(\"cuda\")\n","final_error = torch.mean(abs(final_model_class - test_true_class))\n","print(\"Final error with optimal number of components:\", final_error)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S4HbPTP_F_zY","executionInfo":{"status":"ok","timestamp":1728644078741,"user_tz":-540,"elapsed":2886,"user":{"displayName":"Jaewon Youm","userId":"13291960395408720790"}},"outputId":"5cde66f6-acdc-4193-c45a-3315b6d8727f"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["Final error with optimal number of components: tensor(0.1461, device='cuda:0')\n"]}]}]}